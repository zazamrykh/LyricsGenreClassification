{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f637fa2",
   "metadata": {},
   "source": [
    "## Here we will use zero-shot learning method as baseline for genre classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c89bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e9aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 01:58:34,693 - numexpr.utils - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2025-06-18 01:58:34,693 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from src.utils import logger, DatasetTypes\n",
    "from src.data import init_data\n",
    "from src.metrics import GenrePredictorInterface, evaluate_model\n",
    "from src.model import get_pretrained\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dd3494",
   "metadata": {},
   "source": [
    "## Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e98cc299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer, model = get_pretrained(model_name, device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d5c27",
   "metadata": {},
   "source": [
    "## Get dataset with all genres and 1,294,054 examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a459fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = '../data/all_genres_downsampled.csv'\n",
    "train_dataset, val_dataset, test_dataset , idx2genre, genres, traid_loader, val_loader, test_loader = init_data(path_to_csv=path_to_csv, batch_size=16, tokenizer=tokenizer, dataset_type=DatasetTypes.hundred, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78edb1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = '''You are a music genre expert. You will determine whether a song belongs to a specific genre based on its lyrics. You will be provided with a JSON input containing the lyrics and the target genre. Respond with 1 if the song likely belongs to the specified genre, and 0 if it does not.\n",
    "\n",
    "**Input format:**\n",
    "```json\n",
    "{\n",
    "    \"lyrics\": \"Lyrics of the song\",\n",
    "    \"genre\": \"Target genre\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Output format:**\n",
    "```json\n",
    "{\n",
    "    \"predict\": 1  // if the song belongs to the genre\n",
    "    // or\n",
    "    \"predict\": 0  // if it does not\n",
    "}\n",
    "```\n",
    "\n",
    "**Lyrics with genre for classification:**\n",
    "```json\n",
    "{\n",
    "    \"lyrics\": \"%s\",\n",
    "    \"genre\": \"%s\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Your output**:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c06c4",
   "metadata": {},
   "source": [
    "## Main mechanic and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7123789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main functions\n",
    "def get_input_text(lyrics, genre, enable_thinking=False):\n",
    "    instruct = PROMPT % (lyrics, genre)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": instruct}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=enable_thinking,\n",
    "        max_thinking_tokens=50,\n",
    "        do_sample=False\n",
    "    )\n",
    "    \n",
    "    return text\n",
    "\n",
    "def parse_model_response(generated_ids, model_inputs_len):\n",
    "    assert generated_ids.ndim == 1\n",
    "    \n",
    "    output_ids = generated_ids[model_inputs_len:].tolist() \n",
    "    try:\n",
    "        index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "        \n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "    assert len(content) != 0, 'Error. Output content is empty!'\n",
    "    return thinking_content, content\n",
    "\n",
    "def parse_output_json(response: str) -> int:\n",
    "    try:\n",
    "        match = re.search(r'\\{[^}]*\"predict\"\\s*:\\s*(0|1)[^}]*\\}', response)\n",
    "        if match:\n",
    "            data = json.loads(match.group(0))\n",
    "            return int(data[\"predict\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Parse error: {e}\")\n",
    "    return 0  # fallback to 0 if anything goes wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ec4dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "You are a music genre expert. You will determine whether a song belongs to a specific genre based on its lyrics. You will be provided with a JSON input containing the lyrics and the target genre. Respond with 1 if the song likely belongs to the specified genre, and 0 if it does not.\n",
      "\n",
      "**Input format:**\n",
      "```json\n",
      "{\n",
      "    \"lyrics\": \"Lyrics of the song\",\n",
      "    \"genre\": \"Target genre\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Output format:**\n",
      "```json\n",
      "{\n",
      "    \"predict\": 1  // if the song belongs to the genre\n",
      "    // or\n",
      "    \"predict\": 0  // if it does not\n",
      "}\n",
      "```\n",
      "\n",
      "**Lyrics with genre for classification:**\n",
      "```json\n",
      "{\n",
      "    \"lyrics\": \"[Verse 1] Well, I'm standing here, freezing, outside your golden garden Uh got my ladder, leaned up against your wall Tonight's the night we planned to run away together Come on Dolly Mae, there's no time to stall But now you're telling me [Chorus] I think I better wait until tomorrow I think I bett\",\n",
      "    \"genre\": \"jazz\"\n",
      "}\n",
      "```\n",
      "\n",
      "**Your output**:\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "thinking content: <think>\n",
      "Okay, let's see. The user provided a song's lyrics and a target genre, and I need to determine if it's likely to belong to that genre. The input is a JSON with lyrics and genre. The output should be 1 or 0.\n",
      "\n",
      "Looking at the lyrics: \"[Verse 1] Well, I'm standing here, freezing, outside your golden garden Uh got my ladder, leaned up against your wall Tonight's the night we planned to run away together Come on Dolly Mae, there's no time to stall But now you're telling me [Chorus] I think I better wait until tomorrow I think I bett\".\n",
      "\n",
      "The genre mentioned is \"jazz\". Now, I need to check if the lyrics fit into a jazz context. Jazz often features instruments like piano, saxophone, and rhythms. The lyrics mention a ladder leaning against a wall, which might be a metaphor for a jazz setting. The chorus talks about waiting until tomorrow, which could relate to the improvisational nature of jazz. However, I should be careful not to overgeneralize. Are there any other elements that might indicate a different genre? The lyrics don't mention other genres like pop or rock. So, based on the provided lyrics and the target genre \"jazz\", I think the answer is 1.\n",
      "</think>\n",
      "content: ```json\n",
      "{\n",
      "    \"predict\": 1\n",
      "}\n",
      "```\n",
      "result answer: 1\n"
     ]
    }
   ],
   "source": [
    "lyrics = val_dataset[0]['features']['lyrics']\n",
    "target_genre = val_dataset[0]['features']['genre_list'][0]\n",
    "\n",
    "truncated = lyrics[:300]\n",
    "\n",
    "input_text = get_input_text(truncated, target_genre, enable_thinking=True)\n",
    "print(input_text)\n",
    "\n",
    "model_inputs = tokenizer([input_text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=1337\n",
    ")\n",
    "\n",
    "thinking_content, content = parse_model_response(generated_ids[0], len(model_inputs.input_ids[0]))\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)\n",
    "\n",
    "result = parse_output_json(content)\n",
    "print(f\"result answer: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d9efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also functions for batched generation\n",
    "def build_prompts_and_map(\n",
    "    self, lyrics_list: List[str]\n",
    ") -> Tuple[List[str], List[int]]:\n",
    "    prompts, idx_map = [], []\n",
    "    for idx, txt in enumerate(lyrics_list):\n",
    "        trunc = txt[: self.max_lyrics_length]\n",
    "        for _g in self.genres:\n",
    "            prompts.append(self.prompt_template % (trunc, _g))\n",
    "            idx_map.append(idx)\n",
    "    return prompts, idx_map\n",
    "\n",
    "\n",
    "def get_input_texts_for_each_genre(sample: str, genres: List, enable_thinking=False):\n",
    "    input_texts = []\n",
    "    \n",
    "    for genre in genres:\n",
    "        input_text = get_input_text(sample, genre, enable_thinking=enable_thinking)\n",
    "        input_texts.append(input_text) \n",
    "    \n",
    "    return input_texts \n",
    "\n",
    "\n",
    "def proccess_sample(sample: str, genres: List, truncation_len: int = 300, max_new_tokens: int = 1337, enable_thinking=False) -> np.array:\n",
    "    ''' Make predictions for one sample: whether it belongs to each genre. \n",
    "        Returns np array with 1 in corresponding places if lyrics belongs to genre.'''\n",
    "\n",
    "    truncated = sample[:truncation_len]\n",
    "    \n",
    "    input_texts = get_input_texts_for_each_genre(truncated, genres, enable_thinking=enable_thinking)\n",
    "    \n",
    "    model_inputs_all_genres = tokenizer(input_texts, return_tensors=\"pt\", padding=True, padding_side='left').to(model.device)\n",
    "    \n",
    "    generated_ids_all_genres = model.generate(\n",
    "        **model_inputs_all_genres,\n",
    "        max_new_tokens=max_new_tokens\n",
    "    )\n",
    "    \n",
    "    preds = np.zeros(len(genres), dtype=np.int32)\n",
    "    for i, (generated_ids, model_inputs) in enumerate(zip(generated_ids_all_genres, model_inputs_all_genres['input_ids'])):\n",
    "        thinking_content, content = parse_model_response(generated_ids, len(model_inputs))\n",
    "        result = parse_output_json(content)\n",
    "        preds[i] = result\n",
    "        \n",
    "    return preds\n",
    "\n",
    "def one_hot_encoded_to_genre_list(predictions, idx2genre: dict = None):\n",
    "    ''' Predictions is array on n_genres size, where 1 if lyrics belongs to that genre and 0 if not'''    \n",
    "    genre_list = []\n",
    "    for i, value in enumerate(predictions):\n",
    "        if value == 1:\n",
    "            genre_list.append(idx2genre[i])\n",
    "    \n",
    "    return genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5f740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A relapse of my body Sends my mind into multiple seizures Psychologically a new human being One that has never been Cursed by the shamen his voodoo spell has my soul My limbs go numb I can't control my own thought Are his now his evil consuming me ever telling me begin the clit carving Slowly turning me, into a flesh eating zombie Knowing this spell can only be broken by the vaginal skins of young women I proceed to find the meat their bleeding cunts will set me free Warmth seeping from this Body Rotted After I sucked the blood from her ass I feel more alive more alive than I've ever been Even though now I'm dead within My mouth drools As I slice your perinium My body smeared With the guts I've extracted through her hole, came swollen organs cunnilingus with the mutilated My spirit returned from the dead Released by the priest but I felt more real when I was dead The curse is broken I have a dependence on vaginal skin It's become my sexual addiction I must slit, the twitching clit Rotted cavity hold the juice Between the legs, I love to carve My cock is dripping with her blood\n",
      "[0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
      " 1 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0\n",
      " 0 1 0 1 0 1 1 0 0 0 1 1 1 0]\n",
      "['alt-rock', 'alternative', 'axé', 'blues', 'cloud-rap', 'death-metal', 'deathcore', 'doom-metal', 'dream-pop', 'dub', 'electro-pop', 'electronic', 'electronica', 'emo', 'emo-rap', 'folk', 'forró', 'funk', 'funk-carioca', 'grunge', 'hard-rock', 'hardcore', 'heavy-metal', 'hip-hop', 'indie-pop', 'indie-rock', 'j-pop', 'j-rock', 'jovem-guarda', 'melodic-death-metal', 'metal', 'pagode', 'pop-rock', 'post-punk', 'power-metal', 'power-pop', 'progressive-metal', 'progressive-rock', 'psychedelic', 'psychedelic-rock', 'r&b', 'rap', 'reggae', 'reggaeton', 'religion', 'rock', 'screamo', 'shoegaze', 'soul', 'swing', 'trance', 'trap', 'trip-hop']\n"
     ]
    }
   ],
   "source": [
    "sample = val_dataset[1]['features']['lyrics']\n",
    "print(sample)\n",
    "\n",
    "preds = proccess_sample(sample, genres)\n",
    "print(preds)\n",
    "\n",
    "genre_list = one_hot_encoded_to_genre_list(preds, idx2genre)\n",
    "print(genre_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec8c59",
   "metadata": {},
   "source": [
    "## Metrics evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36688927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluation through dataset\n",
    "\n",
    "class ZeroShotClassifier(GenrePredictorInterface):\n",
    "    def predict(self, batch_features: dict) -> np.array:\n",
    "        list_pred = []\n",
    "        \n",
    "        for features in batch_features['features']:\n",
    "            lyrics = features['lyrics']\n",
    "            \n",
    "            pred = proccess_sample(lyrics, genres)\n",
    "            list_pred.append(pred)\n",
    "\n",
    "        return np.stack(list_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c37a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 ... 1 1 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [1 1 1 ... 1 1 0]\n",
      " [0 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "zero_shot_classifier = ZeroShotClassifier()\n",
    "\n",
    "batch = next(iter(val_loader))\n",
    "\n",
    "result = zero_shot_classifier.predict(batch)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7760005b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [05:33<00:00, 47.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.01956986669338165\n",
      "Recall: 0.4130279442779443\n",
      "F1-score: 0.0349194116910554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_model(zero_shot_classifier, test_loader)\n",
    "\n",
    "print(\"Precision:\", metrics['precision'])\n",
    "print(\"Recall:\", metrics['recall'])\n",
    "print(\"F1-score:\", metrics['f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
